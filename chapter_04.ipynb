{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install -Uqq fastbook \n",
    "import fastbook \n",
    "fastbook.setup_book()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from fastai.vision.all import * \n",
    "from fastbook import * "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Further Research]()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Create your own implementation of `Learner` from scratch, based on the "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import * \n",
    "\n",
    "\n",
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets == 1, 1 - predictions, predictions).mean()\n",
    "\n",
    "\n",
    "def build_dset(path_three, path_seven):\n",
    "    threes = _build_tensor_from_image(path_three)\n",
    "    sevens = _build_tensor_from_image(path_seven)\n",
    "    return _build_dset(threes, sevens)\n",
    "\n",
    "\n",
    "def _build_dset(threes, sevens):\n",
    "    x = torch.cat([threes, sevens])\n",
    "    x = x.view(-1, 28 * 28)\n",
    "    y = tensor([1] * len(threes) + [0] * len(sevens))\n",
    "    y = y.unsqueeze(1)\n",
    "    return list(zip(x, y))\n",
    "    \n",
    "    \n",
    "def _build_tensor_from_image(path):\n",
    "    x = path.ls().sorted()\n",
    "    x = [tensor(Image.open(image_path)) for image_path in x]\n",
    "    return torch.stack(x).float() / 255\n",
    "\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    predictions = xb.sigmoid()\n",
    "    correct = (predictions > 0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "    \n",
    "class BasicOptim:\n",
    "    def __init__(self, params, learning_rate):\n",
    "        self.params = list(params)\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def step(self, *args, **kwargs):\n",
    "        for param in self.params:\n",
    "            param.data -= param.grad.data * self.learning_rate\n",
    "            \n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for param in self.params:\n",
    "            param.grad = None \n",
    "            \n",
    "            \n",
    "class CustomLearner:\n",
    "    def __init__(self, dls, model, opt, loss_func, metrics=accuracy):\n",
    "        self.train_dl = dls[0]\n",
    "        self.valid_dl = dls[1]\n",
    "        self.model = model \n",
    "        self.opt = opt\n",
    "        self.loss_func = loss_func\n",
    "        self.metrics = metrics\n",
    "        \n",
    "    def fit(self, n_epochs, learning_rate):\n",
    "        self.train_model(n_epochs)\n",
    "        \n",
    "    def train_model(self, n_epochs):\n",
    "        for _ in range(n_epochs):\n",
    "            self.train_epoch()\n",
    "            print(self.validate_epoch(), end=\"\\n\")\n",
    "            \n",
    "    def train_epoch(self):\n",
    "        for xb, yb in self.train_dl:\n",
    "            self.calc_grad(xb, yb)\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "            \n",
    "    def calc_grad(self, xb, yb):\n",
    "        predictions = self.model(xb)\n",
    "        loss = self.loss_func(predictions, yb)\n",
    "        loss.backward()\n",
    "            \n",
    "    def validate_epoch(self):\n",
    "        accuracies = [self.metrics(self.model(xb), yb) for xb, yb in self.valid_dl]\n",
    "        return round(torch.stack(accuracies).mean().item(), 4)\n",
    "\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "path.ls()\n",
    "\n",
    "train_dset = build_dset(path/\"train\"/\"3\", path/\"train\"/\"7\")\n",
    "valid_dset = build_dset(path/\"valid\"/\"3\", path/\"valid\"/\"7\")\n",
    "\n",
    "train_dl = DataLoader(train_dset, batch_size=256)\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "\n",
    "linear_model = nn.Linear(28 * 28, 1)\n",
    "\n",
    "opt = BasicOptim(linear_model.parameters(), 1.)\n",
    "\n",
    "custom_learner = CustomLearner(\n",
    "    dls, \n",
    "    linear_model, \n",
    "    opt=opt,\n",
    "    loss_func=mnist_loss,\n",
    "    metrics=batch_accuracy,\n",
    ")\n",
    "\n",
    "custom_learner.fit(5, 0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Complete all the steps in this chapter using the full MNIST datasets (that is, for all digits, not just 3s and 7s)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "def build_x(path):\n",
    "    x = get_image_files(path).sorted()\n",
    "    x = [tensor(Image.open(image_path)) for image_path in x]\n",
    "    x = torch.stack(x)\n",
    "    x = x.float() / 255\n",
    "    return x.view(-1, 28 * 28)\n",
    "\n",
    "def build_y(path):\n",
    "    y = get_image_files(path).sorted()\n",
    "    y = [int(image_path.parent.name) for image_path in y]\n",
    "    return tensor(y)\n",
    "\n",
    "def build_dl(x, y):\n",
    "    dset = list(zip(x, y))\n",
    "    return DataLoader(dset, batch_size=256, shuffle=True)\n",
    "\n",
    "path = untar_data(URLs.MNIST)\n",
    "path.ls()\n",
    "\n",
    "\n",
    "(train_x, train_y) = (build_x(path/\"training\"), build_y(path/\"training\"))\n",
    "train_dl = build_dl(train_x, train_y)\n",
    "\n",
    "(valid_x, valid_y) = (build_x(path/\"testing\"), build_y(path/\"testing\"))\n",
    "valid_dl = build_dl(valid_x, valid_y)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28 * 28, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10)\n",
    ")\n",
    "\n",
    "learner = Learner(\n",
    "    dls, \n",
    "    simple_net, \n",
    "    opt_func=SGD, \n",
    "    loss_func=nn.CrossEntropyLoss(),\n",
    "    metrics=accuracy,\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "learner.fit(10, 0.1)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "1114d05621ef29e6570c6f64184b372ef2b76e47e3b31dc67323ed4052f14a39"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}